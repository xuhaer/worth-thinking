{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树建模\n",
    "对于sklearn中的决策树，参看[DecisionTree](https://github.com/xuhaer/ML/blob/master/Code/Day%2025_Decision_Tree.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对某个web站点的用户行为及其最终购买决策：\n",
    "列: 来源网站，位置，是否阅读过FAQ，浏览网页数，最终购买类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [['slashdot', 'USA', 'yes', 18, 'None'],\n",
    "               ['google', 'France', 'yes', 23, 'Premium'],\n",
    "               ['digg', 'USA', 'yes', 24, 'Basic'],\n",
    "               ['kiwitobes', 'France', 'yes', 23, 'Basic'],\n",
    "               ['google', 'UK', 'no', 21, 'Premium'],\n",
    "               ['(direct)', 'New Zealand', 'no', 12, 'None'],\n",
    "               ['(direct)', 'UK', 'no', 21, 'Basic'],\n",
    "               ['google', 'USA', 'no', 24, 'Premium'],\n",
    "               ['slashdot', 'France', 'yes', 19, 'None'],\n",
    "               ['digg', 'USA', 'no', 18, 'None'],\n",
    "               ['google', 'UK', 'no', 18, 'None'],\n",
    "               ['kiwitobes', 'UK', 'no', 19, 'None'],\n",
    "               ['digg', 'New Zealand', 'yes', 12, 'Basic'],\n",
    "               ['slashdot', 'UK', 'no', 21, 'None'],\n",
    "               ['google', 'UK', 'yes', 18, 'Basic'],\n",
    "               ['kiwitobes', 'France', 'yes', 19, 'Basic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入决策树：\n",
    "* col是待检测的判断条件所对应的列索引值。\n",
    "* value对应于为了使结果为true,当前列必须匹配的值。\n",
    "* tb、fb为decisionnode，对应与true或false时的子树\n",
    "* results保存的是针对于当前分支的结果，是一个字典。除叶节点外，在其它节点上该值均为None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decisionnode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col = col\n",
    "        self.value = value\n",
    "        self.results = results\n",
    "        self.tb = tb\n",
    "        self.fb = fb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divideset的作用是根据列表中某一栏的数据将列表拆分为两个数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideset(rows, column, value):\n",
    "    # Make a function that tells us if a row is in\n",
    "    # the first group (true) or the second group (false)\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "            split_function = lambda row: row[column] >= value\n",
    "    else:\n",
    "            split_function = lambda row: row[column] == value\n",
    "    # Divide the rows into two sets and return them\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return (set1, set2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如根据第二列的值是否为'yes'将my_data拆分为2个集合:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['slashdot', 'USA', 'yes', 18, 'None'],\n",
       "  ['google', 'France', 'yes', 23, 'Premium'],\n",
       "  ['digg', 'USA', 'yes', 24, 'Basic'],\n",
       "  ['kiwitobes', 'France', 'yes', 23, 'Basic'],\n",
       "  ['slashdot', 'France', 'yes', 19, 'None'],\n",
       "  ['digg', 'New Zealand', 'yes', 12, 'Basic'],\n",
       "  ['google', 'UK', 'yes', 18, 'Basic'],\n",
       "  ['kiwitobes', 'France', 'yes', 19, 'Basic']],\n",
       " [['google', 'UK', 'no', 21, 'Premium'],\n",
       "  ['(direct)', 'New Zealand', 'no', 12, 'None'],\n",
       "  ['(direct)', 'UK', 'no', 21, 'Basic'],\n",
       "  ['google', 'USA', 'no', 24, 'Premium'],\n",
       "  ['digg', 'USA', 'no', 18, 'None'],\n",
       "  ['google', 'UK', 'no', 18, 'None'],\n",
       "  ['kiwitobes', 'UK', 'no', 19, 'None'],\n",
       "  ['slashdot', 'UK', 'no', 21, 'None']])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divideset(my_data, 2, 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设第二列是否为'yes'与用户最终购买服务有直接关系， 基于上面的结果可知：yes: 2 None, 1 Pre, 5 Basic, no: 5 None, 2 Pre, 1 Basic\n",
    "\n",
    "结果并非很理想，而且，也不直观，因此我们需要引入一种方法来“衡量”其“理想化”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对各种可能的结果进行计数，返回一个字典，其中包含了每一项结果的出现次数，为接下来计算数据集合的复杂度函数提供依据。\n",
    "def uniquecounts(rows):\n",
    "    results = {}\n",
    "    for row in rows:\n",
    "            # The result is the last column\n",
    "            r = row[len(row)-1]\n",
    "            if r not in results: results[r] = 0\n",
    "            results[r] += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于混杂程度的测试，有几种不同的度量方式可供选择，此处我们将考察其中的两种：<font color='red'>**基尼不纯度(Gini impurity) 和 熵(entropy)** <font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **基尼不纯度**：是指将来自集合中的某种结果随机应用于集合中的某一数据项的预期误差率。\n",
    "<br>\n",
    "基尼不纯度的计算函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniimpurity(rows):\n",
    "    total = len(rows)\n",
    "    results = uniquecounts(rows)\n",
    "    imp = 0\n",
    "    for k1 in results:\n",
    "        p1 = float(results[k1]) / total\n",
    "        for k2 in results:\n",
    "            if k1 == k2: continue\n",
    "            p2 = float(results[k2]) / total\n",
    "            imp += p1*p2\n",
    "    return imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **熵**: 在信息理论中，熵代表的是集合的无序程度--基本上就相当于我们在此处所说的集合的混杂程度。\n",
    "\n",
    "如果所有结果都相同(比如此例中，不论怎样，最终所有人都成为了付费用户),则熵为0。群组越是混乱，则其熵就越高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 熵是遍历所有可能的结果之后所得到的p(x)*log(p(x))之和\n",
    "def entropy(rows):\n",
    "    from math import log\n",
    "    log2 = lambda x: log(x)/log(2) #换底公式\n",
    "    results = uniquecounts(rows)\n",
    "    # Now calculate the entropy\n",
    "    ent = 0.0\n",
    "    for r in results.keys():\n",
    "            p = float(results[r])/len(rows)\n",
    "            ent = ent-p*log2(p)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6328125"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " giniimpurity(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5052408149441479"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1, set2 = divideset(my_data, 2, 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看根据第二列是否阅读FAQ拆分后的数据集的混杂程度："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giniimpurity(set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2987949406953985"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(set1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，基尼不纯度减少约0.1，熵减少约0.2， 熵和基尼不纯度的主要区别在于：熵达到峰值的过程要相对慢一些。因此，熵对于混乱集合的‘判罚’要更重一些。 由于人们对熵的使用更为普遍，此后的将选择熵作为度量标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以递归的方式构造树\n",
    "为了弄明白一个属性的好坏程度，我们的算法是首先求出整个群组的熵，然后尝试利用每个属性的可能取值对群组进行拆分，并求出两个新群组的熵。为了确定哪个属性最合适用来拆分，算法会计算相应的<font color='red'> **信息增益(information gain)** </font>, 所谓信息增益，指当前熵与两个新群组经加权后的熵之间的差值。算法会针对每个属性计算相应的信息增益，然后从中选出信息增益最大的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildtree(rows, scoref=entropy):\n",
    "    '''接受一个由数据行构成的列表作为参数。遍历了数据集中的每一列(最后一列除外，那是同来存放最终结果的)，\n",
    "    针对各列查找的每一列可能的取值，并将数据集拆分为两个新的子集。通过将子集的熵乘以子集中所含数据项在\n",
    "    原数据集中所占的比重(fraction)，函数求出了每一列对新生成的子集的加权平均熵，并记录下熵值最低的那一对子集。\n",
    "    如果由熵值最低的一对子集求的的加权平均熵比当前集合的熵大，拆分结束。否则，递归调用，并把调用的结果添加到树上。'''\n",
    "    if len(rows)==0:\n",
    "        return decisionnode()\n",
    "    current_score=scoref(rows)\n",
    "\n",
    "    # Set up some variables to track the best criteria\n",
    "    best_gain=0.0\n",
    "    best_criteria=None\n",
    "    best_sets=None\n",
    "    \n",
    "    column_count=len(rows[0])-1\n",
    "    for col in range(0,column_count):\n",
    "        # Generate the list of different values in\n",
    "        # this column\n",
    "        column_values={}\n",
    "        for row in rows:\n",
    "             column_values[row[col]]=1\n",
    "        # Now try dividing the rows up for each value\n",
    "        # in this column\n",
    "        for value in column_values.keys():\n",
    "            (set1,set2)=divideset(rows,col,value)\n",
    "            \n",
    "            # Information gain\n",
    "            # 信息增益：当前熵与两个新群组经加权后的熵之间的差值\n",
    "            p=float(len(set1))/len(rows)\n",
    "            gain=current_score-p*scoref(set1)-(1-p)*scoref(set2)\n",
    "            if gain>best_gain and len(set1)>0 and len(set2)>0:\n",
    "                best_gain=gain\n",
    "                best_criteria=(col,value)\n",
    "                best_sets=(set1,set2)\n",
    "    # Create the sub branches       \n",
    "    if best_gain>0:\n",
    "        trueBranch=buildtree(best_sets[0])\n",
    "        falseBranch=buildtree(best_sets[1])\n",
    "        return decisionnode(col=best_criteria[0],value=best_criteria[1],\n",
    "                                                tb=trueBranch,fb=falseBranch)\n",
    "    else:\n",
    "        return decisionnode(results=uniquecounts(rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = buildtree(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 树的显示\n",
    "tree为我们得到的一棵决策树，下一步即是树的浏览："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printtree(tree, indent=''):\n",
    "    # Is this a leaf node?\n",
    "    if tree.results != None:\n",
    "            print(str(tree.results))\n",
    "    else:\n",
    "            # Print the criteria\n",
    "            print(str(tree.col)+':'+str(tree.value)+'? ')\n",
    "            # Print the branches\n",
    "            print(indent+'T->', end=' ')\n",
    "            printtree(tree.tb, indent+'  ')\n",
    "            print(indent+'F->', end=' ')\n",
    "            printtree(tree.fb, indent+'  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:google? \n",
      "T-> 3:21? \n",
      "  T-> {'Premium': 3}\n",
      "  F-> 2:no? \n",
      "    T-> {'None': 1}\n",
      "    F-> {'Basic': 1}\n",
      "F-> 0:slashdot? \n",
      "  T-> {'None': 3}\n",
      "  F-> 2:yes? \n",
      "    T-> {'Basic': 4}\n",
      "    F-> 3:21? \n",
      "      T-> {'Basic': 1}\n",
      "      F-> {'None': 3}\n"
     ]
    }
   ],
   "source": [
    "printtree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的printtree以文本的形式显示, 随着树的规模逐渐变大，以这样的可视化形式来追踪我们在树上所走的路径可能是非常困难。此外，我们以一种图形化表现形式来展示树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getwidth(tree):\n",
    "    if tree.tb == None and tree.fb == None: return 1\n",
    "    return getwidth(tree.tb)+getwidth(tree.fb)\n",
    "\n",
    "\n",
    "def getdepth(tree):\n",
    "    if tree.tb == None and tree.fb == None: return 0\n",
    "    return max(getdepth(tree.tb), getdepth(tree.fb))+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def drawtree(tree, jpeg='tree.jpg'):\n",
    "    \"\"\"为待绘制的树确定一个合理的尺寸，并设置好画布(canvas)，然后将画布和树的根节点传递给drawnode\"\"\"\n",
    "    w = getwidth(tree)*100\n",
    "    h = getdepth(tree)*100+120\n",
    "\n",
    "    img = Image.new('RGB', (w, h), (255, 255, 255))\n",
    "    canvas = ImageDraw.Draw(img)\n",
    "\n",
    "    drawnode(canvas, tree, w/2, 20)\n",
    "    img.save(jpeg, 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawnode(canvas, tree, x, y):\n",
    "    if tree.results == None:\n",
    "        # Get the width of each branch\n",
    "        w1 = getwidth(tree.fb)*100\n",
    "        w2 = getwidth(tree.tb)*100\n",
    "\n",
    "        # Determine the total space required by this node\n",
    "        left = x-(w1+w2)/2\n",
    "        right = x+(w1+w2)/2\n",
    "\n",
    "        # Draw the condition string\n",
    "        canvas.text((x-20, y-10), str(tree.col)+':'+str(tree.value), (0, 0, 0))\n",
    "\n",
    "        # Draw links to the branches\n",
    "        canvas.line((x, y, left+w1/2, y+100), fill=(255, 0, 0))\n",
    "        canvas.line((x, y, right-w2/2, y+100), fill=(255, 0, 0))\n",
    "\n",
    "        # Draw the branch nodes\n",
    "        drawnode(canvas, tree.fb, left+w1/2, y+100)\n",
    "        drawnode(canvas, tree.tb, right-w2/2, y+100)\n",
    "    else:\n",
    "        txt = ' \\n'.join(['%s:%d' % v for v in tree.results.items()])\n",
    "        canvas.text((x-20, y), txt, (0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawtree(tree, jpeg='../datasets/treeview.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果如下:![treeview.jpg](../datasets/treeview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对新的观测数据进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(observation, tree):\n",
    "    \"\"\"该函数采用与printtree完全相同的方式对树进行遍历。在每次调用之后，函数会根据调用结果来判断是否到达分支的末端。\"\"\"\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        branch = None\n",
    "        if isinstance(v, int) or isinstance(v, float):\n",
    "            if v >= tree.value: branch = tree.tb\n",
    "            else: branch = tree.fb\n",
    "        else:\n",
    "            if v == tree.value: branch = tree.tb\n",
    "            else: branch = tree.fb\n",
    "        return classify(observation, branch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，依据前面已经构造的tree来预测一个新的观测数据:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Premium': 3}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(['google', 'China', 'yes', 23], tree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们已经能够从任何数据集中构造决策树，显示和解释决策树的函数，以及对新的数据进行预测的函数。但上述代码仍有缺陷: 过拟合(overfitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树的剪枝\n",
    "前述方法可能会有过拟合的问题--也就是说，它可能变得过于针对训练数据。因为前述算法直到无法再近一步降低熵的时候才会停止分支的创建过程，所以一种可能的解决方法是：**只要当熵减少的数量小于某个阈值时就停止分支的创建。**\n",
    "\n",
    "这种策略时常被人们采用，但是它有一个小小的缺陷--我们有可能会遇到这样的数据集: 某一次分支的创建并不会令熵降低多少，但是随后创建的分支却会使熵大幅降低。对此，一种替代的策略是，先构造好如前所述的整棵树，然后再尝试消除多余的节点--**剪枝**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**剪枝的过程就是对具有相同父节点的一组节点进行检查，判断如果将其合并，熵的增加量是否会小于某个指定的阈值。如果是，则说明这些节点合并后对混杂度的影响在‘可接受’范围内，将会并合并成一个单一的节点。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(tree, mingain):\n",
    "    # If the branches aren't leaves, then prune them\n",
    "    if tree.tb.results == None:\n",
    "        prune(tree.tb, mingain)\n",
    "    if tree.fb.results == None:\n",
    "        prune(tree.fb, mingain)\n",
    "\n",
    "    # If both the subbranches are now leaves, see if they\n",
    "    # should merged\n",
    "    if tree.tb.results != None and tree.fb.results != None:\n",
    "        # Build a combined dataset\n",
    "        tb, fb = [], []\n",
    "        for v, c in tree.tb.results.items():\n",
    "            tb += [[v]]*c\n",
    "        for v, c in tree.fb.results.items():\n",
    "            fb += [[v]]*c\n",
    "\n",
    "        # Test the reduction in entropy\n",
    "        delta = entropy(tb+fb)-(entropy(tb)+entropy(fb)/2)\n",
    "\n",
    "        if delta < mingain:\n",
    "            # Merge the branches\n",
    "            tree.tb, tree.fb = None, None\n",
    "            tree.results = uniquecounts(tb+fb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对当前的数据，看看剪枝后的效果：(这个例子中，数据的拆分很容易，只要将最小增益值调得非常高的时候，某个节点才会被合并)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prune(tree, 0.9)\n",
    "drawtree(tree, jpeg='../datasets/pruned_treeview.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img scr='pruned_treeview.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img scr='pruned_treeview.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pruned_treeview.jpg](../datasets/pruned_treeview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，决策树还有一个有点，就是它处理缺失数据的能力。我们所使用的数据集也许会缺失某些信息--比如，用户的地理位置未必能够从其IP地址中识别出来。\n",
    "\n",
    "如果缺失了某些数据，而这些数据是确定是否分支走向所必需的，那么实际上我们可以选择两个分支都走。不过，我们不是平均地统计各分支对应的结果值，而是对其进行加权统计。\n",
    "\n",
    "为了实现上诉功能，mdclassify是对classify的一个简单修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdclassify(observation, tree):\n",
    "    if tree.results != None:\n",
    "        return tree.results\n",
    "    else:\n",
    "        v = observation[tree.col]\n",
    "        if v == None:\n",
    "            tr, fr = mdclassify(observation, tree.tb), mdclassify(\n",
    "                    observation, tree.fb)\n",
    "            tcount = sum(tr.values())\n",
    "            fcount = sum(fr.values())\n",
    "            tw = float(tcount)/(tcount+fcount)\n",
    "            fw = float(fcount)/(tcount+fcount)\n",
    "            result = {}\n",
    "            for k, v in tr.items(): result[k] = v*tw\n",
    "            for k, v in fr.items(): result[k] = v*fw\n",
    "            return result\n",
    "        else:\n",
    "            if isinstance(v, int) or isinstance(v, float):\n",
    "                if v >= tree.value: branch = tree.tb\n",
    "                else: branch = tree.fb\n",
    "            else:\n",
    "                if v == tree.value: branch = tree.tb\n",
    "                else: branch = tree.fb\n",
    "            return mdclassify(observation, branch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mdclassify 与 classify 相比， 唯一的区别在于if v == None 那里: 如果发现有重要数据缺失，则每个分支的对应结果值都会被计算一遍，并在最终的结果值乘于它们各自的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Premium': 2.25, 'Basic': 0.25}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdclassify(['google', None, 'yes', None], tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Premium': 2.25, 'None': 0.125, 'Basic': 0.125}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdclassify(['google', 'France', None, None], tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么时候使用决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或许决策树的最大优势在于它可以轻易地对一个受训模型给予解释。\n",
    "\n",
    "此外，与其它几种机器学习算法不同，决策树可以同时接受分类(categorical)数据和数值(numerical)数据作为输入。不仅如此，许多算法在运行之前都要求我们必须对输入数据做预处理，或是归一化处理，而本例中的代码却可以接受包括分类数据和数值数据在内的任何数据列表。\n",
    "\n",
    "决策树还允许数据的不确定性分配(mdclassify允许我们使用'None'来表示一个值的缺失)，对数值型数据而言，其结果也许会落在某个已知的范围内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过，决策树算法还是有缺陷的。虽然对于只包含少数几种可能结果的问题而言，算法处理起来非常有效，但当面对大量可能结果的数据集时，算法就变得不那么有效了。\n",
    "\n",
    "前述的决策树还有一个较大的缺陷，尽管它可以处理简单的数值类型数据，但是它只能创建满足“>/<”条件的节点。对于某些数据，决定分类的因素往往取决于更多变量的复杂组合，例如，假设结果值是由两个变量的差来决定的，那么这棵树就会变得非常庞大，而且预测的准确性也会迅速下降。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**综上，对于有大量数值型输入和输出的问题，决策树未必是一个好的选择；如果数值型输入之间存在许多错综复杂的关系，决策树也不是一个好的选择。**\n",
    "\n",
    "**决策树最适合用来处理的是那些带分界点(breakpoints)的、由大量分类数据和数值数据共同组成的数据集。如果对决策过程的理解至关重要，那么采用决策树就再合适不过了。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
